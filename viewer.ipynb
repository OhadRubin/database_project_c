{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get POSTGRES_ADDRESS from .env file\n",
    "POSTGRES_ADDRESS = os.getenv(\"POSTGRES_ADDRESS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create engine with the address\n",
    "engine = create_engine(POSTGRES_ADDRESS)\n",
    "def get_sim_runs():\n",
    "    df = pd.read_sql_query(\"SELECT * FROM benchmark_runs_v2\", engine)\n",
    "    # Set pandas display options to make tables wider\n",
    "    pd.set_option('display.max_columns', None)  # Show all columns\n",
    "    pd.set_option('display.width', 1000)        # Set width to 1000 characters\n",
    "    pd.set_option('display.expand_frame_repr', False)  # Don't wrap to multiple lines\n",
    "    # Drop the 'args' column if it exists in the DataFrame\n",
    "    # if 'args' in df.columns:\n",
    "    # df = df.drop(columns=['config_details_json'])\n",
    "    return df.query(\"id>1\")\n",
    "sim_df = get_sim_runs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fp(row):\n",
    "    if row[\"implementation\"].startswith(\"nd\"):\n",
    "        ro_met =  row[\"metrics\"][\"nd_metrics\"]\n",
    "        row[\"fp_micro\"] = ro_met[\"false_positive_count\"]/ro_met[\"total_pairs\"]\n",
    "        row[\"fp_macro\"] = ro_met[\"false_positive_rate\"]\n",
    "    else:\n",
    "        ro_met =  row[\"metrics\"][\"cl_metrics\"][-1]\n",
    "        row[\"fp_micro\"] =  ro_met[\"total_false_positive_count\"]/ro_met[\"total_total_pairs\"]\n",
    "        row[\"fp_macro\"] = ro_met[\"total_false_positive_rate\"]\n",
    "        \n",
    "        \n",
    "\n",
    "    return row\n",
    "        \n",
    "sim_df = sim_df.apply(get_fp, axis=1)\n",
    "view_sim_df = sim_df.drop(columns=[\"ngram_size\", \"min_ngram_size\", \"num_perm\", \"limit_files\", \"num_nodes\", \"record_count\", \"duplicate_count\", \"input_file\", \"timestamp\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>threshold</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>total_size_gb</th>\n",
       "      <th>config_details_json</th>\n",
       "      <th>metrics</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_micro</th>\n",
       "      <th>fp_macro</th>\n",
       "      <th>exp_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Experiment: datasize | Workflow: nd_cl | Limit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1868.719052</td>\n",
       "      <td>2.972425</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...</td>\n",
       "      <td>{'nd_time': 1481.2580375671387, 'nd_metrics': ...</td>\n",
       "      <td>0.777375</td>\n",
       "      <td>0.777375</td>\n",
       "      <td>0.453621</td>\n",
       "      <td>nd_cl_datasize_files10_thresh0.7_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Experiment: datasize | Workflow: cl_nd | Limit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>445.153823</td>\n",
       "      <td>2.972425</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...</td>\n",
       "      <td>{'cl_nd_time': 444.95437932014465, 'cl_metrics...</td>\n",
       "      <td>0.759419</td>\n",
       "      <td>0.759419</td>\n",
       "      <td>0.440791</td>\n",
       "      <td>cl_nd_datasize_files10_thresh0.7_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Experiment: datasize | Workflow: nd_cl | Limit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1892.470000</td>\n",
       "      <td>5.942862</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...</td>\n",
       "      <td>{'nd_time': 1439.3975429534912, 'nd_metrics': ...</td>\n",
       "      <td>0.793228</td>\n",
       "      <td>0.793228</td>\n",
       "      <td>0.467767</td>\n",
       "      <td>nd_cl_datasize_files20_thresh0.7_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experiment: datasize | Workflow: cl_nd | Limit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>649.734896</td>\n",
       "      <td>5.942862</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...</td>\n",
       "      <td>{'cl_nd_time': 649.5374999046326, 'cl_metrics'...</td>\n",
       "      <td>0.790332</td>\n",
       "      <td>0.790332</td>\n",
       "      <td>0.416310</td>\n",
       "      <td>cl_nd_datasize_files20_thresh0.7_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Experiment: datasize | Workflow: nd_cl | Limit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2253.195967</td>\n",
       "      <td>11.883736</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...</td>\n",
       "      <td>{'nd_time': 1634.2958981990814, 'nd_metrics': ...</td>\n",
       "      <td>0.822215</td>\n",
       "      <td>0.822215</td>\n",
       "      <td>0.470901</td>\n",
       "      <td>nd_cl_datasize_files40_thresh0.7_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Experiment: datasize | Workflow: cl_nd | Limit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1420.974992</td>\n",
       "      <td>11.883736</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...</td>\n",
       "      <td>{'cl_nd_time': 1420.7762591838837, 'cl_metrics...</td>\n",
       "      <td>0.819333</td>\n",
       "      <td>0.819333</td>\n",
       "      <td>0.430796</td>\n",
       "      <td>cl_nd_datasize_files40_thresh0.7_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Experiment: threshold | Workflow: nd_cl | Limi...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4941.537140</td>\n",
       "      <td>11.883736</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...</td>\n",
       "      <td>{'nd_time': 4324.399260759354, 'nd_metrics': {...</td>\n",
       "      <td>0.731658</td>\n",
       "      <td>0.731658</td>\n",
       "      <td>0.361330</td>\n",
       "      <td>nd_cl_threshold_files40_thresh0.6_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Experiment: threshold | Workflow: cl_nd | Limi...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4070.318676</td>\n",
       "      <td>11.883736</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...</td>\n",
       "      <td>{'cl_nd_time': 4070.123877763748, 'cl_metrics'...</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>0.347450</td>\n",
       "      <td>cl_nd_threshold_files40_thresh0.6_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Experiment: threshold | Workflow: nd_cl | Limi...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2641.562159</td>\n",
       "      <td>11.883736</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...</td>\n",
       "      <td>{'nd_time': 1966.7177550792694, 'nd_metrics': ...</td>\n",
       "      <td>0.822215</td>\n",
       "      <td>0.822215</td>\n",
       "      <td>0.470901</td>\n",
       "      <td>nd_cl_threshold_files40_thresh0.7_perm256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Experiment: threshold | Workflow: cl_nd | Limi...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1649.138648</td>\n",
       "      <td>11.883736</td>\n",
       "      <td>{\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...</td>\n",
       "      <td>{'cl_nd_time': 1648.934634923935, 'cl_metrics'...</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.813762</td>\n",
       "      <td>0.441867</td>\n",
       "      <td>cl_nd_threshold_files40_thresh0.7_perm256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                notes  threshold  execution_time  total_size_gb                                config_details_json                                            metrics        fp  fp_micro  fp_macro                                   exp_name\n",
       "1   Experiment: datasize | Workflow: nd_cl | Limit...        0.7     1868.719052       2.972425  {\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...  {'nd_time': 1481.2580375671387, 'nd_metrics': ...  0.777375  0.777375  0.453621   nd_cl_datasize_files10_thresh0.7_perm256\n",
       "2   Experiment: datasize | Workflow: cl_nd | Limit...        0.7      445.153823       2.972425  {\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...  {'cl_nd_time': 444.95437932014465, 'cl_metrics...  0.759419  0.759419  0.440791   cl_nd_datasize_files10_thresh0.7_perm256\n",
       "3   Experiment: datasize | Workflow: nd_cl | Limit...        0.7     1892.470000       5.942862  {\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...  {'nd_time': 1439.3975429534912, 'nd_metrics': ...  0.793228  0.793228  0.467767   nd_cl_datasize_files20_thresh0.7_perm256\n",
       "4   Experiment: datasize | Workflow: cl_nd | Limit...        0.7      649.734896       5.942862  {\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...  {'cl_nd_time': 649.5374999046326, 'cl_metrics'...  0.790332  0.790332  0.416310   cl_nd_datasize_files20_thresh0.7_perm256\n",
       "5   Experiment: datasize | Workflow: nd_cl | Limit...        0.7     2253.195967      11.883736  {\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...  {'nd_time': 1634.2958981990814, 'nd_metrics': ...  0.822215  0.822215  0.470901   nd_cl_datasize_files40_thresh0.7_perm256\n",
       "6   Experiment: datasize | Workflow: cl_nd | Limit...        0.7     1420.974992      11.883736  {\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...  {'cl_nd_time': 1420.7762591838837, 'cl_metrics...  0.819333  0.819333  0.430796   cl_nd_datasize_files40_thresh0.7_perm256\n",
       "7   Experiment: threshold | Workflow: nd_cl | Limi...        0.6     4941.537140      11.883736  {\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...  {'nd_time': 4324.399260759354, 'nd_metrics': {...  0.731658  0.731658  0.361330  nd_cl_threshold_files40_thresh0.6_perm256\n",
       "8   Experiment: threshold | Workflow: cl_nd | Limi...        0.6     4070.318676      11.883736  {\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...  {'cl_nd_time': 4070.123877763748, 'cl_metrics'...  0.725581  0.725581  0.347450  cl_nd_threshold_files40_thresh0.6_perm256\n",
       "9   Experiment: threshold | Workflow: nd_cl | Limi...        0.7     2641.562159      11.883736  {\\n  \"args\": {\\n    \"workflow\": \"nd_cl\",\\n    ...  {'nd_time': 1966.7177550792694, 'nd_metrics': ...  0.822215  0.822215  0.470901  nd_cl_threshold_files40_thresh0.7_perm256\n",
       "10  Experiment: threshold | Workflow: cl_nd | Limi...        0.7     1649.138648      11.883736  {\\n  \"args\": {\\n    \"workflow\": \"cl_nd\",\\n    ...  {'cl_nd_time': 1648.934634923935, 'cl_metrics'...  0.813762  0.813762  0.441867  cl_nd_threshold_files40_thresh0.7_perm256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_sim_df = view_sim_df.assign(exp_name=view_sim_df.output_dir.str.split(\"/\").str[-1]).drop(columns=[\"output_dir\", \"implementation\"])\n",
    "view_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_sim_df.iloc[:7].to_csv(\"view_sim_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/nd_cl_datasize_files10_thresh0.7_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/cl_nd_datasize_files10_thresh0.7_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/nd_cl_datasize_files20_thresh0.7_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/cl_nd_datasize_files20_thresh0.7_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/nd_cl_datasize_files40_thresh0.7_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/cl_nd_datasize_files40_thresh0.7_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/nd_cl_threshold_files40_thresh0.6_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/cl_nd_threshold_files40_thresh0.6_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/nd_cl_threshold_files40_thresh0.7_perm256',\n",
       " '/mnt/gcs_bucket/ray_experiment_outputs_20250414_135126/cl_nd_threshold_files40_thresh0.7_perm256']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_sim_df.output_dir.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nd_time': 1481.2580375671387,\n",
       " 'nd_metrics': {'duplicate_count': 76548,\n",
       "  'execution_time': 58.258687257766724,\n",
       "  'false_positive_rate': 0.45362053328706475,\n",
       "  'false_positive_count': 4337294.0,\n",
       "  'total_pairs': 5579412.0},\n",
       " 'cl_time': 385.1235592365265,\n",
       " 'cl_metrics': [{'inference_time': 23.118709325790405,\n",
       "   'train_time': 134.10090136528015,\n",
       "   'total_time': 161.22191190719604,\n",
       "   'stage': 'stage1'},\n",
       "  {'inference_time': 13.681020927429199,\n",
       "   'train_time': 129.9850064277649,\n",
       "   'total_time': 223.72447180747986,\n",
       "   'stage': 'stage2',\n",
       "   'total_false_positive_count': 0,\n",
       "   'total_false_positive_rate': 0.0,\n",
       "   'total_total_pairs': 0}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df.metrics.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for a,b in zip(df.metrics.tolist(), df.implementation.tolist()):\n",
    "#     fp = get_fp()\n",
    "#     print(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m, in \u001b[0;36mget_fp\u001b[0;34m(metrics)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfalse_positive_count\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m/\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_pairs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'false_positive_count'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a,b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mtolist(), df\u001b[38;5;241m.\u001b[39mimplementation\u001b[38;5;241m.\u001b[39mtolist()):\n\u001b[0;32m----> 3\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mget_fp\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcl_metrics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(b,a)\n",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m, in \u001b[0;36mget_fp\u001b[0;34m(metrics)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse_positive_count\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_pairs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_false_positive_count\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_total_pairs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "for a,b in zip(df.metrics.tolist(), df.implementation.tolist()):\n",
    "\n",
    "    fp = get_fp(a[\"cl_metrics\"][-1])\n",
    "    print(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(df.metrics.tolist(), df.notes.tolist()):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.iloc[1:].to_csv(\"benchmark_runs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.execution_time.sum()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicate_count+df.record_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.7*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "752.379005/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "421_609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13831082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13_831_082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1_749_756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"/home/ohadr/database_project_c/benchmark_results.db\")\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM benchmark_runs\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\"duplicate_count\",\"record_count\",\"execution_time\", \"total_size_gb\"]].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
