{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'timestamp', 'input_file', 'output_dir', 'notes', 'duplicate_count', 'record_count', 'implementation', 'num_nodes', 'threshold', 'ngram_size', 'min_ngram_size', 'num_perm', 'execution_time', 'limit_files', 'total_size_gb', 'metrics'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get POSTGRES_ADDRESS from .env file\n",
    "POSTGRES_ADDRESS = os.getenv(\"POSTGRES_ADDRESS\")\n",
    "\n",
    "# Create engine with the address\n",
    "engine = create_engine(POSTGRES_ADDRESS)\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM benchmark_runs_v2\", engine)\n",
    "# Set pandas display options to make tables wider\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)        # Set width to 1000 characters\n",
    "pd.set_option('display.expand_frame_repr', False)  # Don't wrap to multiple lines\n",
    "# Drop the 'args' column if it exists in the DataFrame\n",
    "# if 'args' in df.columns:\n",
    "df = df.drop(columns=['config_details_json'])\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nd_metrics': {'duplicate_count': 16056,\n",
       "   'execution_time': 84.51909303665161,\n",
       "   'false_positive_rate': 0.43359419653890957},\n",
       "  'cl_metrics': [{'inference_time': 0.0,\n",
       "    'train_time': 0.0,\n",
       "    'total_time': 2.12062406539917,\n",
       "    'stage': 'stage1'},\n",
       "   {'inference_time': 11.204771542549134,\n",
       "    'train_time': 14.100396943092345,\n",
       "    'total_time': 89.97783589363098,\n",
       "    'stage': 'stage2'}]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metrics.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.iloc[1:].to_csv(\"benchmark_runs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.execution_time.sum()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicate_count+df.record_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.7*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "752.379005/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "421_609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13831082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13_831_082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1_749_756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"/home/ohadr/database_project_c/benchmark_results.db\")\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM benchmark_runs\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\"duplicate_count\",\"record_count\",\"execution_time\", \"total_size_gb\"]].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
